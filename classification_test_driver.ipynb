{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "from chatnet.general_classifier_model import ClassifierPipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, RandomForestRegressor, AdaBoostRegressor, BaggingRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LassoLars, BayesianRidge, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sets up the sample data frame\n",
    "def str_to_list(s):\n",
    "    return s[1:-1].split(\", u\")\n",
    "df = pd.read_csv(\"chatnet/5-25msg_score.tsv\", sep=\"\\t\")\n",
    "df[\"msgs\"] = df[\"msgs\"].apply(str_to_list)\n",
    "\n",
    "# Sample feature data of 4-tuple of standard normals\n",
    "features = zip(np.random.standard_normal(df.shape[0]), np.random.standard_normal(df.shape[0]), \n",
    "               np.random.standard_normal(df.shape[0]), np.random.standard_normal(df.shape[0]))\n",
    "\n",
    "# If you don't want features, have empty arrays\n",
    "# features = [[] for _ in range(df.shape[0])]\n",
    "\n",
    "df[\"features\"] = pd.Series(features)\n",
    "df_sample = df.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default SVC: 0.866666666667\n"
     ]
    }
   ],
   "source": [
    "# Defaults to SVC\n",
    "cl_pipe = ClassifierPipeline(positive_class=\"satisfaction\")\n",
    "cl_pipe.setup(df_sample)\n",
    "cl_pipe.run()\n",
    "print \"default SVC:\", cl_pipe.cl.test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost: 0.466666666667\n",
      "Random Forest: 0.766666666667\n"
     ]
    }
   ],
   "source": [
    "# Running with arguments\n",
    "\n",
    "# Single list of tuple of classifier, arguments\n",
    "cl_pipe = ClassifierPipeline(positive_class=\"satisfaction\")\n",
    "cl_pipe.setup(df_sample)\n",
    "cl_pipe.run([(AdaBoostClassifier, {\"n_estimators\": 100})])\n",
    "print \"AdaBoost:\", cl_pipe.cl.test_score\n",
    "\n",
    "# Classifier, arguments\n",
    "cl_pipe.run(RandomForestClassifier, class_weight = {0: 2, 1: 1})\n",
    "print \"Random Forest:\", cl_pipe.cl.test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lists of classifiers and regressors to test\n",
    "classifiers = [KNeighborsClassifier, [(SVC, {\"probability\": True})], DecisionTreeClassifier, RandomForestClassifier, AdaBoostClassifier, GaussianNB, LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis]\n",
    "regressors = [KNeighborsRegressor, SVR, DecisionTreeRegressor, RandomForestRegressor, AdaBoostRegressor, BaggingRegressor, LinearRegression, Ridge, BayesianRidge, LogisticRegression]\n",
    "classifier_sets = [[(SVC, {\"probability\": True, \"cache_size\": 3000}), (GaussianNB, )], [(SVC, {\"probability\": True, \"cache_size\": 3000}), (GaussianNB,), (DecisionTreeClassifier, {\"class_weight\": {0: 2, 1: 1}})]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TESTING SINGLE CLASSIFIERS\n",
      "\n",
      "single classifier: <class 'sklearn.neighbors.classification.KNeighborsClassifier'> 0.133333333333\n",
      "single classifier: [(<class 'sklearn.svm.classes.SVC'>, {'probability': True})] 0.966666666667\n",
      "single classifier: <class 'sklearn.tree.tree.DecisionTreeClassifier'> 0.1\n",
      "single classifier: <class 'sklearn.ensemble.forest.RandomForestClassifier'> 0.666666666667\n",
      "single classifier: <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'> 0.533333333333\n",
      "single classifier: <class 'sklearn.naive_bayes.GaussianNB'> 0.0333333333333\n",
      "single classifier: <class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'> 0.566666666667\n",
      "single classifier: <class 'sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis'> 0.166666666667\n",
      "\n",
      "TESTING ENSEMBLE VOTING CLASSIFIERS\n",
      "\n",
      "SOFT VOTING\n",
      "soft set: [(<class 'sklearn.svm.classes.SVC'>, {'cache_size': 3000, 'probability': True}), (<class 'sklearn.naive_bayes.GaussianNB'>,)] 0.0333333333333\n",
      "\n",
      "HARD VOTING\n",
      "hard set: [(<class 'sklearn.svm.classes.SVC'>, {'cache_size': 3000, 'probability': True}), (<class 'sklearn.naive_bayes.GaussianNB'>,)] 0.0333333333333\n",
      "\n",
      "SOFT VOTING\n",
      "soft set: [(<class 'sklearn.svm.classes.SVC'>, {'cache_size': 3000, 'probability': True}), (<class 'sklearn.naive_bayes.GaussianNB'>,), (<class 'sklearn.tree.tree.DecisionTreeClassifier'>, {'class_weight': {0: 2, 1: 1}})] 0.133333333333\n",
      "\n",
      "HARD VOTING\n",
      "hard set: [(<class 'sklearn.svm.classes.SVC'>, {'cache_size': 3000, 'probability': True}), (<class 'sklearn.naive_bayes.GaussianNB'>,), (<class 'sklearn.tree.tree.DecisionTreeClassifier'>, {'class_weight': {0: 2, 1: 1}})] 0.1\n",
      "\n",
      "TESTING REGRESSORS\n",
      "\n",
      "regression: <class 'sklearn.neighbors.regression.KNeighborsRegressor'> -0.831669044223\n",
      "regression: <class 'sklearn.svm.classes.SVR'> -0.167886341363\n",
      "regression: <class 'sklearn.tree.tree.DecisionTreeRegressor'> -0.0271041369472\n",
      "regression: <class 'sklearn.ensemble.forest.RandomForestRegressor'> 0.112410841655\n",
      "regression: <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'> -0.064684713762\n",
      "regression: <class 'sklearn.ensemble.bagging.BaggingRegressor'> 0.159058487874\n",
      "regression: <class 'sklearn.linear_model.base.LinearRegression'> -0.873396692265\n",
      "regression: <class 'sklearn.linear_model.ridge.Ridge'> -0.850568963669\n",
      "regression: <class 'sklearn.linear_model.bayes.BayesianRidge'> -0.847414504514\n",
      "regression: <class 'sklearn.linear_model.logistic.LogisticRegression'> 0.666666666667\n"
     ]
    }
   ],
   "source": [
    "print \"\\nTESTING SINGLE CLASSIFIERS\\n\"\n",
    "for classifier in classifiers:\n",
    "    cl_pipe = ClassifierPipeline(positive_class=\"satisfaction\")\n",
    "    cl_pipe.setup(df_sample)\n",
    "    cl_pipe.run(classifier)\n",
    "    print \"single classifier:\", classifier, cl_pipe.cl.test_score\n",
    "\n",
    "print \"\\nTESTING ENSEMBLE VOTING CLASSIFIERS\"\n",
    "for cl_set in classifier_sets:\n",
    "\n",
    "    # Ensemble voting with soft voting\n",
    "    print \"\\nSOFT VOTING\"\n",
    "    cl_set_soft_pipe = ClassifierPipeline(positive_class=\"satisfaction\")\n",
    "    cl_set_soft_pipe.setup(df_sample)\n",
    "    cl_set_soft_pipe.run(cl_set, voting=\"soft\")\n",
    "    print \"soft set:\", cl_set, cl_set_soft_pipe.cl.test_score\n",
    "\n",
    "    # Ensemble voting with hard voting\n",
    "    print \"\\nHARD VOTING\"\n",
    "    cl_set_hard_pipe = ClassifierPipeline(positive_class=\"satisfaction\")\n",
    "    cl_set_hard_pipe.setup(df_sample)\n",
    "    cl_set_hard_pipe.run(cl_set)\n",
    "    print \"hard set:\", cl_set, cl_set_hard_pipe.cl.test_score\n",
    "\n",
    "print \"\\nTESTING REGRESSORS\\n\"\n",
    "for regressor in regressors:\n",
    "    reg_pipe = ClassifierPipeline(positive_class=\"scores\")\n",
    "    reg_pipe.setup(df_sample)\n",
    "    reg_pipe.run(regressor)\n",
    "    print \"regression:\", regressor, reg_pipe.cl.test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
